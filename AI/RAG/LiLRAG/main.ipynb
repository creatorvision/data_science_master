{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG DEVELOPMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index>=0.10.37 (from -r requirements.txt (line 1))Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for llama-index>=0.10.37 from https://files.pythonhosted.org/packages/1f/9e/dde209ac22a94c5d08ddc02713975a0f620831c1b02d6283ad0ec7ff62e3/llama_index-0.11.6-py3-none-any.whl.metadata\n",
      "  Using cached llama_index-0.11.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting qdrant-client>=1.9.1 (from -r requirements.txt (line 2))\n",
      "  Obtaining dependency information for qdrant-client>=1.9.1 from https://files.pythonhosted.org/packages/70/e9/b4f75f0916d6661259667410f7bf5887b742f3d2662bfe1c809671b80b34/qdrant_client-1.11.1-py3-none-any.whl.metadata\n",
      "  Using cached qdrant_client-1.11.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: llama-index-readers-file>=0.1.22 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (0.1.33)\n",
      "Collecting llama-index-vector-stores-qdrant>=0.2.8 (from -r requirements.txt (line 4))\n",
      "  Obtaining dependency information for llama-index-vector-stores-qdrant>=0.2.8 from https://files.pythonhosted.org/packages/f6/29/0f34cb258eb118e60f014fb5208bcfe6202d29fb4d78eeec723cd9b96ee2/llama_index_vector_stores_qdrant-0.3.0-py3-none-any.whl.metadata\n",
      "  Using cached llama_index_vector_stores_qdrant-0.3.0-py3-none-any.whl.metadata (767 bytes)\n",
      "Collecting cohere>=5.5.0 (from -r requirements.txt (line 5))\n",
      "  Obtaining dependency information for cohere>=5.5.0 from https://files.pythonhosted.org/packages/8d/3d/44d32712658c7186a423204c758d74143611289d22939d117df888b5d078/cohere-5.9.1-py3-none-any.whl.metadata\n",
      "  Using cached cohere-5.9.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: openai>=1.30.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (1.31.1)\n",
      "Collecting llama-index-llms-cohere>=0.2.0 (from -r requirements.txt (line 7))\n",
      "  Obtaining dependency information for llama-index-llms-cohere>=0.2.0 from https://files.pythonhosted.org/packages/f5/7b/5c38be510ca1158cc0047d3618d4d9980d426f0b0a07de45415aff1cf1f9/llama_index_llms_cohere-0.3.0-py3-none-any.whl.metadata\n",
      "  Using cached llama_index_llms_cohere-0.3.0-py3-none-any.whl.metadata (675 bytes)\n",
      "Requirement already satisfied: llama-index-llms-openai>=0.1.19 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 8)) (0.1.31)\n",
      "Collecting llama-index-embeddings-cohere>=0.1.8 (from -r requirements.txt (line 9))\n",
      "  Obtaining dependency information for llama-index-embeddings-cohere>=0.1.8 from https://files.pythonhosted.org/packages/c5/76/da5f7d9a84a3085cd033986f17955cf8f192d56b94fdbf7bce8101eee25f/llama_index_embeddings_cohere-0.2.0-py3-none-any.whl.metadata\n",
      "  Using cached llama_index_embeddings_cohere-0.2.0-py3-none-any.whl.metadata (693 bytes)\n",
      "Requirement already satisfied: llama-index-embeddings-openai>=0.1.9 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 10)) (0.1.11)\n",
      "Collecting llama-index-postprocessor-cohere-rerank>=0.1.6 (from -r requirements.txt (line 11))\n",
      "  Obtaining dependency information for llama-index-postprocessor-cohere-rerank>=0.1.6 from https://files.pythonhosted.org/packages/91/69/361686a7dbc1bbf80dc1776f34f72ef4f412bd17cb374b2362ac245eabb8/llama_index_postprocessor_cohere_rerank-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_postprocessor_cohere_rerank-0.2.0-py3-none-any.whl.metadata (723 bytes)\n",
      "Collecting llama-index-agent-openai<0.4.0,>=0.3.0 (from llama-index>=0.10.37->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for llama-index-agent-openai<0.4.0,>=0.3.0 from https://files.pythonhosted.org/packages/b9/e3/f0fd37795337132ade36ae9e189def1430ea2db474614c55fa1033a0daf4/llama_index_agent_openai-0.3.0-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_agent_openai-0.3.0-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-cli<0.4.0,>=0.3.0 (from llama-index>=0.10.37->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for llama-index-cli<0.4.0,>=0.3.0 from https://files.pythonhosted.org/packages/dd/c2/3bb98c98dc1f782783ae48fd75b84cfa2742ae41c2e508d2a87f6db52101/llama_index_cli-0.3.0-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_cli-0.3.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.12.0,>=0.11.6 (from llama-index>=0.10.37->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for llama-index-core<0.12.0,>=0.11.6 from https://files.pythonhosted.org/packages/05/3b/4cfe3adb49223901ac405fae1670551509ccb8193d374c172f4a1add938c/llama_index_core-0.11.6-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_core-0.11.6-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama-index-embeddings-openai>=0.1.9 (from -r requirements.txt (line 10))\n",
      "  Obtaining dependency information for llama-index-embeddings-openai>=0.1.9 from https://files.pythonhosted.org/packages/ba/0a/b22567c0677312ef8a42f96d274eac3ccafb2c3fd202f0a56bf8846b6153/llama_index_embeddings_openai-0.2.4-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_embeddings_openai-0.2.4-py3-none-any.whl.metadata (635 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama-index>=0.10.37->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for llama-index-indices-managed-llama-cloud>=0.3.0 from https://files.pythonhosted.org/packages/23/2d/123c6646532dbf0afa119ce014d2f4e625aa8eacc49dc928d2b757e86603/llama_index_indices_managed_llama_cloud-0.3.0-py3-none-any.whl.metadata\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index>=0.10.37->-r requirements.txt (line 1)) (0.9.48.post3)\n",
      "Collecting llama-index-llms-openai>=0.1.19 (from -r requirements.txt (line 8))\n",
      "  Obtaining dependency information for llama-index-llms-openai>=0.1.19 from https://files.pythonhosted.org/packages/95/f2/367a47b4b1c7e2c0fd751edab5881bcfb53aca78e3953cedf071c3f714f9/llama_index_llms_openai-0.2.2-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_llms_openai-0.2.2-py3-none-any.whl.metadata (705 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama-index>=0.10.37->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 from https://files.pythonhosted.org/packages/33/ab/9bc1c12b88ccc252c66de9021b88766cb4223bfd10940da47aa41d7cc3e5/llama_index_multi_modal_llms_openai-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.2.0-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama-index>=0.10.37->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for llama-index-program-openai<0.3.0,>=0.2.0 from https://files.pythonhosted.org/packages/1e/67/45422d24aad29191f3a9eb621afa0feb491653f1cb012d51083824d36c7b/llama_index_program_openai-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama-index>=0.10.37->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for llama-index-question-gen-openai<0.3.0,>=0.2.0 from https://files.pythonhosted.org/packages/35/97/64691f3b3a5be2bea75102b189818276c7b2ddf688050e387954b176623a/llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file>=0.1.22 (from -r requirements.txt (line 3))\n",
      "  Obtaining dependency information for llama-index-readers-file>=0.1.22 from https://files.pythonhosted.org/packages/57/44/6fe4b9ef73a5444e88badd9484b2b76b89de8811d704c25ba6e23adc63ed/llama_index_readers_file-0.2.1-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_readers_file-0.2.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.3.0 (from llama-index>=0.10.37->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for llama-index-readers-llama-parse>=0.3.0 from https://files.pythonhosted.org/packages/49/b2/174bb131b767f9873b9f95b6c216043ccde4cfbeb3bcaf01fa23594f810a/llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index>=0.10.37->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for nltk>3.8.1 from https://files.pythonhosted.org/packages/4d/66/7d9e26593edda06e8cb531874633f7c2372279c3b0f46235539fe546df8b/nltk-3.9.1-py3-none-any.whl.metadata\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from qdrant-client>=1.9.1->-r requirements.txt (line 2)) (1.66.1)\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client>=1.9.1->-r requirements.txt (line 2))\n",
      "  Obtaining dependency information for grpcio-tools>=1.41.0 from https://files.pythonhosted.org/packages/1d/57/406f509cf87120cce56b90421e564669b09c9ea9bff8e29f501d5eb5a6e5/grpcio_tools-1.66.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading grpcio_tools-1.66.1-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: httpx[http2]>=0.20.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from qdrant-client>=1.9.1->-r requirements.txt (line 2)) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from qdrant-client>=1.9.1->-r requirements.txt (line 2)) (1.24.3)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client>=1.9.1->-r requirements.txt (line 2))\n",
      "  Obtaining dependency information for portalocker<3.0.0,>=2.7.0 from https://files.pythonhosted.org/packages/9b/fb/a70a4214956182e0d7a9099ab17d50bfcba1056188e9b14f35b9e2b62a0d/portalocker-2.10.1-py3-none-any.whl.metadata\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from qdrant-client>=1.9.1->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from qdrant-client>=1.9.1->-r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-readers-file>=0.1.22->-r requirements.txt (line 3)) (4.12.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-readers-file>=0.1.22->-r requirements.txt (line 3)) (1.5.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-readers-file>=0.1.22->-r requirements.txt (line 3)) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-readers-file>=0.1.22->-r requirements.txt (line 3)) (0.0.26)\n",
      "Collecting boto3<2.0.0,>=1.34.0 (from cohere>=5.5.0->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for boto3<2.0.0,>=1.34.0 from https://files.pythonhosted.org/packages/3f/91/9b0ee954bbee47edc2c2cd46121cde3a51b132476ed1853a72e2f211b111/boto3-1.35.13-py3-none-any.whl.metadata\n",
      "  Downloading boto3-1.35.13-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere>=5.5.0->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for fastavro<2.0.0,>=1.9.4 from https://files.pythonhosted.org/packages/43/b3/cac5151810a8c8b5ef318b488a61288fe07e623e9b342c3fc2f60cbfdede/fastavro-1.9.7-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading fastavro-1.9.7-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting httpx-sse==0.4.0 (from cohere>=5.5.0->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for httpx-sse==0.4.0 from https://files.pythonhosted.org/packages/e1/9b/a181f281f65d776426002f330c31849b86b31fc9d848db62e16f03ff739f/httpx_sse-0.4.0-py3-none-any.whl.metadata\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting parameterized<0.10.0,>=0.9.0 (from cohere>=5.5.0->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for parameterized<0.10.0,>=0.9.0 from https://files.pythonhosted.org/packages/00/2f/804f58f0b856ab3bf21617cccf5b39206e6c4c94c2cd227bde125ea6105f/parameterized-0.9.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from cohere>=5.5.0->-r requirements.txt (line 5)) (2.20.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from cohere>=5.5.0->-r requirements.txt (line 5)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from cohere>=5.5.0->-r requirements.txt (line 5)) (0.19.1)\n",
      "Collecting types-requests<3.0.0,>=2.0.0 (from cohere>=5.5.0->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for types-requests<3.0.0,>=2.0.0 from https://files.pythonhosted.org/packages/f1/53/9d399872413354e8c3e27ac8da98459cb215b2dfdab29323fffd5ebf2ca4/types_requests-2.32.0.20240905-py3-none-any.whl.metadata\n",
      "  Downloading types_requests-2.32.0.20240905-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from cohere>=5.5.0->-r requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from openai>=1.30.1->-r requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from openai>=1.30.1->-r requirements.txt (line 6)) (1.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\creat\\anaconda3\\lib\\site-packages (from openai>=1.30.1->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from openai>=1.30.1->-r requirements.txt (line 6)) (4.66.5)\n",
      "Collecting openai>=1.30.1 (from -r requirements.txt (line 6))\n",
      "  Obtaining dependency information for openai>=1.30.1 from https://files.pythonhosted.org/packages/41/fd/8406cbaf5100e697a38c6850f07379bb690ba31f08147dbbe47922bc2ecf/openai-1.43.1-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.43.1-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from openai>=1.30.1->-r requirements.txt (line 6)) (0.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.30.1->-r requirements.txt (line 6)) (3.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file>=0.1.22->-r requirements.txt (line 3)) (2.4)\n",
      "Collecting botocore<1.36.0,>=1.35.13 (from boto3<2.0.0,>=1.34.0->cohere>=5.5.0->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for botocore<1.36.0,>=1.35.13 from https://files.pythonhosted.org/packages/1b/ae/1da883404652d308eecebcd124dacb0d27d924c41ce46c932d82c3f8f714/botocore-1.35.13-py3-none-any.whl.metadata\n",
      "  Downloading botocore-1.35.13-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from boto3<2.0.0,>=1.34.0->cohere>=5.5.0->-r requirements.txt (line 5)) (0.10.0)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.0->cohere>=5.5.0->-r requirements.txt (line 5))\n",
      "  Obtaining dependency information for s3transfer<0.11.0,>=0.10.0 from https://files.pythonhosted.org/packages/3c/4a/b221409913760d26cf4498b7b1741d510c82d3ad38381984a3ddc135ec66/s3transfer-0.10.2-py3-none-any.whl.metadata\n",
      "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-tools>=1.41.0->qdrant-client>=1.9.1->-r requirements.txt (line 2))\n",
      "  Obtaining dependency information for protobuf<6.0dev,>=5.26.1 from https://files.pythonhosted.org/packages/de/f7/e7e03be7e7307123f6467080f283e484de7e892db54dd9a46f057d08c9ee/protobuf-5.28.0-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-5.28.0-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\users\\creat\\anaconda3\\lib\\site-packages (from grpcio-tools>=1.41.0->qdrant-client>=1.9.1->-r requirements.txt (line 2)) (68.0.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client>=1.9.1->-r requirements.txt (line 2)) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client>=1.9.1->-r requirements.txt (line 2)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->-r requirements.txt (line 2)) (0.14.0)\n",
      "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client>=1.9.1->-r requirements.txt (line 2))\n",
      "  Obtaining dependency information for h2<5,>=3 from https://files.pythonhosted.org/packages/2a/e5/db6d438da759efbb488c4f3fbdab7764492ff3c3f953132efa6b9f0e9e53/h2-4.1.0-py3-none-any.whl.metadata\n",
      "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (2024.6.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (9.4.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (1.14.1)\n",
      "Requirement already satisfied: llama-cloud>=0.0.11 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index>=0.10.37->-r requirements.txt (line 1)) (0.0.14)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.3.0->llama-index>=0.10.37->-r requirements.txt (line 1))\n",
      "  Obtaining dependency information for llama-parse>=0.5.0 from https://files.pythonhosted.org/packages/15/a4/a1402d586995010d836116fdd6e633315a2d50f0b229251f66c68010feb3/llama_parse-0.5.2-py3-none-any.whl.metadata\n",
      "  Downloading llama_parse-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: click in c:\\users\\creat\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index>=0.10.37->-r requirements.txt (line 1)) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\creat\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index>=0.10.37->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from nltk>3.8.1->llama-index>=0.10.37->-r requirements.txt (line 1)) (2022.7.9)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from portalocker<3.0.0,>=2.7.0->qdrant-client>=1.9.1->-r requirements.txt (line 2)) (305.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pydantic>=1.10.8->qdrant-client>=1.9.1->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere>=5.5.0->-r requirements.txt (line 5)) (3.3.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tokenizers<1,>=0.15->cohere>=5.5.0->-r requirements.txt (line 5)) (0.24.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tqdm>4->openai>=1.30.1->-r requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pandas->llama-index-readers-file>=0.1.22->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pandas->llama-index-readers-file>=0.1.22->-r requirements.txt (line 3)) (2022.7)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (1.8.1)\n",
      "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->-r requirements.txt (line 2))\n",
      "  Obtaining dependency information for hyperframe<7,>=6.0 from https://files.pythonhosted.org/packages/d7/de/85a784bcc4a3779d1753a7ec2dee5de90e18c7bcf402e71b51fcf150b129/hyperframe-6.0.1-py3-none-any.whl.metadata\n",
      "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->-r requirements.txt (line 2))\n",
      "  Obtaining dependency information for hpack<5,>=4.0 from https://files.pythonhosted.org/packages/d5/34/e8b383f35b77c402d28563d2b8f83159319b509bc5f760b15d60b0abf165/hpack-4.0.0-py3-none-any.whl.metadata\n",
      "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\creat\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.5.0->-r requirements.txt (line 5)) (3.15.4)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.5.0->-r requirements.txt (line 5)) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->llama-index-readers-file>=0.1.22->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.6->llama-index>=0.10.37->-r requirements.txt (line 1)) (3.22.0)\n",
      "Downloading llama_index-0.11.6-py3-none-any.whl (6.8 kB)\n",
      "Downloading qdrant_client-1.11.1-py3-none-any.whl (259 kB)\n",
      "   ---------------------------------------- 0.0/259.4 kB ? eta -:--:--\n",
      "   --------------------------------------  256.0/259.4 kB 15.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  256.0/259.4 kB 15.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  256.0/259.4 kB 15.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 259.4/259.4 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading llama_index_readers_file-0.2.1-py3-none-any.whl (38 kB)\n",
      "Downloading llama_index_vector_stores_qdrant-0.3.0-py3-none-any.whl (11 kB)\n",
      "Downloading cohere-5.9.1-py3-none-any.whl (221 kB)\n",
      "   ---------------------------------------- 0.0/221.3 kB ? eta -:--:--\n",
      "   ------------------------------------- - 215.0/221.3 kB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 221.3/221.3 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading llama_index_llms_cohere-0.3.0-py3-none-any.whl (10 kB)\n",
      "Downloading llama_index_llms_openai-0.2.2-py3-none-any.whl (12 kB)\n",
      "Downloading openai-1.43.1-py3-none-any.whl (365 kB)\n",
      "   ---------------------------------------- 0.0/365.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 365.7/365.7 kB 11.5 MB/s eta 0:00:00\n",
      "Downloading llama_index_embeddings_cohere-0.2.0-py3-none-any.whl (4.0 kB)\n",
      "Downloading llama_index_embeddings_openai-0.2.4-py3-none-any.whl (6.1 kB)\n",
      "Downloading llama_index_postprocessor_cohere_rerank-0.2.0-py3-none-any.whl (2.8 kB)\n",
      "Downloading boto3-1.35.13-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.2/139.2 kB 8.1 MB/s eta 0:00:00\n",
      "Downloading fastavro-1.9.7-cp311-cp311-win_amd64.whl (500 kB)\n",
      "   ---------------------------------------- 0.0/500.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 500.1/500.1 kB 30.6 MB/s eta 0:00:00\n",
      "Downloading grpcio_tools-1.66.1-cp311-cp311-win_amd64.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.1/1.1 MB 71.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 34.8 MB/s eta 0:00:00\n",
      "Downloading llama_index_agent_openai-0.3.0-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.3.0-py3-none-any.whl (27 kB)\n",
      "Downloading llama_index_core-0.11.6-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 1.2/1.6 MB 39.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 16.5 MB/s eta 0:00:00\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.3.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.2.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 1.1/1.5 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 15.9 MB/s eta 0:00:00\n",
      "Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading types_requests-2.32.0.20240905-py3-none-any.whl (15 kB)\n",
      "Downloading botocore-1.35.13-py3-none-any.whl (12.5 MB)\n",
      "   ---------------------------------------- 0.0/12.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.0/12.5 MB 42.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.5/12.5 MB 36.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.4/12.5 MB 30.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.2/12.5 MB 27.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.8/12.5 MB 24.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.7/12.5 MB 23.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.4/12.5 MB 23.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.9/12.5 MB 21.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.2/12.5 MB 19.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.5/12.5 MB 18.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.8/12.5 MB 17.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.1/12.5 MB 16.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.4/12.5 MB 15.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.7/12.5 MB 15.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.0/12.5 MB 14.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.4/12.5 MB 14.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.8/12.5 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.9/12.5 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.3/12.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.6/12.5 MB 11.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.0/12.5 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.5 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.5 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.5 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.5 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.5 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.5 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.5 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.5 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.5 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.5 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.5 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.5/12.5 MB 6.7 MB/s eta 0:00:00\n",
      "Using cached h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "Downloading llama_parse-0.5.2-py3-none-any.whl (9.5 kB)\n",
      "Downloading protobuf-5.28.0-cp310-abi3-win_amd64.whl (431 kB)\n",
      "   ---------------------------------------- 0.0/431.5 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 358.4/431.5 kB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 431.5/431.5 kB 6.7 MB/s eta 0:00:00\n",
      "Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "   ---------------------------------------- 0.0/82.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 82.7/82.7 kB 4.5 MB/s eta 0:00:00\n",
      "Using cached hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Using cached hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: types-requests, protobuf, portalocker, parameterized, hyperframe, httpx-sse, hpack, fastavro, nltk, h2, grpcio-tools, botocore, s3transfer, openai, llama-index-core, qdrant-client, llama-parse, llama-index-readers-file, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, boto3, llama-index-vector-stores-qdrant, llama-index-readers-llama-parse, cohere, llama-index-postprocessor-cohere-rerank, llama-index-llms-cohere, llama-index-embeddings-cohere, llama-index-llms-openai, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.24.2\n",
      "    Uninstalling protobuf-4.24.2:\n",
      "      Successfully uninstalled protobuf-4.24.2\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.27.59\n",
      "    Uninstalling botocore-1.27.59:\n",
      "      Successfully uninstalled botocore-1.27.59\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.6.0\n",
      "    Uninstalling s3transfer-0.6.0:\n",
      "      Successfully uninstalled s3transfer-0.6.0\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.31.1\n",
      "    Uninstalling openai-1.31.1:\n",
      "      Successfully uninstalled openai-1.31.1\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.10.32\n",
      "    Uninstalling llama-index-core-0.10.32:\n",
      "      Successfully uninstalled llama-index-core-0.10.32\n",
      "  Attempting uninstall: llama-parse\n",
      "    Found existing installation: llama-parse 0.4.9\n",
      "    Uninstalling llama-parse-0.4.9:\n",
      "      Successfully uninstalled llama-parse-0.4.9\n",
      "  Attempting uninstall: llama-index-readers-file\n",
      "    Found existing installation: llama-index-readers-file 0.1.33\n",
      "    Uninstalling llama-index-readers-file-0.1.33:\n",
      "      Successfully uninstalled llama-index-readers-file-0.1.33\n",
      "  Attempting uninstall: llama-index-indices-managed-llama-cloud\n",
      "    Found existing installation: llama-index-indices-managed-llama-cloud 0.1.6\n",
      "    Uninstalling llama-index-indices-managed-llama-cloud-0.1.6:\n",
      "      Successfully uninstalled llama-index-indices-managed-llama-cloud-0.1.6\n",
      "  Attempting uninstall: llama-index-embeddings-openai\n",
      "    Found existing installation: llama-index-embeddings-openai 0.1.11\n",
      "    Uninstalling llama-index-embeddings-openai-0.1.11:\n",
      "      Successfully uninstalled llama-index-embeddings-openai-0.1.11\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.24.28\n",
      "    Uninstalling boto3-1.24.28:\n",
      "      Successfully uninstalled boto3-1.24.28\n",
      "  Attempting uninstall: llama-index-readers-llama-parse\n",
      "    Found existing installation: llama-index-readers-llama-parse 0.1.6\n",
      "    Uninstalling llama-index-readers-llama-parse-0.1.6:\n",
      "      Successfully uninstalled llama-index-readers-llama-parse-0.1.6\n",
      "  Attempting uninstall: llama-index-llms-openai\n",
      "    Found existing installation: llama-index-llms-openai 0.1.31\n",
      "    Uninstalling llama-index-llms-openai-0.1.31:\n",
      "      Successfully uninstalled llama-index-llms-openai-0.1.31\n",
      "  Attempting uninstall: llama-index-agent-openai\n",
      "    Found existing installation: llama-index-agent-openai 0.2.9\n",
      "    Uninstalling llama-index-agent-openai-0.2.9:\n",
      "      Successfully uninstalled llama-index-agent-openai-0.2.9\n",
      "  Attempting uninstall: llama-index-program-openai\n",
      "    Found existing installation: llama-index-program-openai 0.1.7\n",
      "    Uninstalling llama-index-program-openai-0.1.7:\n",
      "      Successfully uninstalled llama-index-program-openai-0.1.7\n",
      "  Attempting uninstall: llama-index-question-gen-openai\n",
      "    Found existing installation: llama-index-question-gen-openai 0.1.3\n",
      "    Uninstalling llama-index-question-gen-openai-0.1.3:\n",
      "      Successfully uninstalled llama-index-question-gen-openai-0.1.3\n",
      "  Attempting uninstall: llama-index-multi-modal-llms-openai\n",
      "    Found existing installation: llama-index-multi-modal-llms-openai 0.1.9\n",
      "    Uninstalling llama-index-multi-modal-llms-openai-0.1.9:\n",
      "      Successfully uninstalled llama-index-multi-modal-llms-openai-0.1.9\n",
      "  Attempting uninstall: llama-index-cli\n",
      "    Found existing installation: llama-index-cli 0.1.13\n",
      "    Uninstalling llama-index-cli-0.1.13:\n",
      "      Successfully uninstalled llama-index-cli-0.1.13\n",
      "  Attempting uninstall: llama-index\n",
      "    Found existing installation: llama-index 0.10.32\n",
      "    Uninstalling llama-index-0.10.32:\n",
      "      Successfully uninstalled llama-index-0.10.32\n",
      "Successfully installed boto3-1.35.13 botocore-1.35.13 cohere-5.9.1 fastavro-1.9.7 grpcio-tools-1.66.1 h2-4.1.0 hpack-4.0.0 httpx-sse-0.4.0 hyperframe-6.0.1 llama-index-0.11.6 llama-index-agent-openai-0.3.0 llama-index-cli-0.3.0 llama-index-core-0.11.6 llama-index-embeddings-cohere-0.2.0 llama-index-embeddings-openai-0.2.4 llama-index-indices-managed-llama-cloud-0.3.0 llama-index-llms-cohere-0.3.0 llama-index-llms-openai-0.2.2 llama-index-multi-modal-llms-openai-0.2.0 llama-index-postprocessor-cohere-rerank-0.2.0 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.2.1 llama-index-readers-llama-parse-0.3.0 llama-index-vector-stores-qdrant-0.3.0 llama-parse-0.5.2 nltk-3.9.1 openai-1.43.1 parameterized-0.9.0 portalocker-2.10.1 protobuf-5.28.0 qdrant-client-1.11.1 s3transfer-0.10.2 types-requests-2.32.0.20240905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.4.2 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.35.13 which is incompatible.\n",
      "awswrangler 3.4.0 requires packaging<24.0,>=21.1, but you have packaging 24.1 which is incompatible.\n",
      "googleapis-common-protos 1.60.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.28.0 which is incompatible.\n",
      "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.28.0 which is incompatible.\n",
      "google-cloud-bigquery 3.11.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.0 which is incompatible.\n",
      "google-cloud-bigquery-storage 2.22.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.0 which is incompatible.\n",
      "llama-index-embeddings-ollama 0.1.2 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.6 which is incompatible.\n",
      "llama-index-llms-ollama 0.1.2 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.6 which is incompatible.\n",
      "llama-index-readers-web 0.1.10 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.6 which is incompatible.\n",
      "opentelemetry-proto 1.27.0 requires protobuf<5.0,>=3.19, but you have protobuf 5.28.0 which is incompatible.\n",
      "proto-plus 1.22.3 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 5.28.0 which is incompatible.\n",
      "s3fs 2023.3.0 requires fsspec==2023.3.0, but you have fsspec 2024.6.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Function to take pdf from url and save in the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "def download_file(url: str, filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Download a file from a URL and save it to a specified location.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): The URL of the file to download.\n",
    "    filename (str): The name to save the file as.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Construct the destination path\n",
    "    destination = Path('data') / filename\n",
    "    destination.parent.mkdir(parents=True, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an exception if the request was unsuccessful\n",
    "\n",
    "    with open(destination, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    print(f\"File downloaded successfully to {destination}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully to data\\almanack_of_naval_ravikant.pdf\n"
     ]
    }
   ],
   "source": [
    "navalmanack_url = \"https://navalmanack.s3.amazonaws.com/Eric-Jorgenson_The-Almanack-of-Naval-Ravikant_Final.pdf\"\n",
    "download_file(navalmanack_url, \"almanack_of_naval_ravikant.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully to data\\anthology_of_balaji.pdf\n"
     ]
    }
   ],
   "source": [
    "balaji_url = \"https://balajianthology.s3.us-east-2.amazonaws.com/The+Anthology+of+Balaji.pdf\"\n",
    "download_file(balaji_url, \"anthology_of_balaji.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully to data\\taoofseneca_vol1-1.pdf\n",
      "File downloaded successfully to data\\taoofseneca_vol2.pdf\n",
      "File downloaded successfully to data\\taoofseneca_vol3.pdf\n"
     ]
    }
   ],
   "source": [
    "# List of URLs to download\n",
    "letters_urls = [\n",
    "    \"https://tim.blog/wp-content/uploads/2017/07/taoofseneca_vol1-1.pdf\",\n",
    "    \"https://tim.blog/wp-content/uploads/2017/07/taoofseneca_vol2.pdf\",\n",
    "    \"https://tim.blog/wp-content/uploads/2017/07/taoofseneca_vol3.pdf\",\n",
    "]\n",
    "\n",
    "# Loop over the URLs and download each file\n",
    "for url in letters_urls:\n",
    "    filename = Path(url).name  # Extract the filename from the URL\n",
    "    download_file(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully to data\\skin_in_the_game.pdf\n"
     ]
    }
   ],
   "source": [
    "skin_in_the_game_url = \"https://philosophiatopics.files.wordpress.com/2018/10/skin-in-the-game-nassim-nicholas-taleb.pdf\"\n",
    "download_file(skin_in_the_game_url, \"skin_in_the_game.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully to data\\hackers_and_painters.pdf\n"
     ]
    }
   ],
   "source": [
    "hackers_url = \"https://digtvbg.com/files/books-for-hacking/Hackers%20%26%20Painters%20-%20Big%20Ideas%20From%20The%20Computer%20Age%20by%20Paul%20Graham.pdf\"\n",
    "download_file(hackers_url, \"hackers_and_painters.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully to data\\striking-thoughts.pdf\n"
     ]
    }
   ],
   "source": [
    "striking_thoughts = \"https://eddierockerz.com/wp-content/uploads/2020/11/striking-thoughts_-bruce-lees-wisdom-for-daily-living-pdfdrive.com-.pdf\"\n",
    "download_file(url= striking_thoughts, filename= \"striking-thoughts.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CO_API_KEY = os.environ['COHERE_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexander the Great was a king of the ancient Greek kingdom of Macedon and a legendary military commander. He is considered one of the greatest military minds in history, having conquered much of the known world of his time and established an empire that stretched from Greece to northwestern India. He was known for his bold tactics, innovative use of cavalry, and ability to inspire loyalty in his troops. Alexander's conquests had a significant impact on the spread of Greek culture and ideas, a period known as the Hellenistic era, and his legacy continues to be studied and admired by military strategists and historians alike.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.cohere import Cohere\n",
    "\n",
    "llm = Cohere(model=\"command-r-plus\", temperature = 0.2)\n",
    "response = llm.complete(\"Alexander the great was a\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt templates\n",
    "\n",
    " A prompt template is a fundamental input that gives LLMs their expressive power in the LlamaIndex framework.\n",
    "\n",
    " It's used to build the index, perform insertions, traverse during querying, and synthesize the final answer.\n",
    "\n",
    " LlamaIndex has several built-in prompt templates.\n",
    "\n",
    " Below is how you can create one from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
