{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama3 RAG Model \n",
    "\n",
    "Download Ollama https://ollama.com/download\n",
    "\n",
    "Run Ollama run llama3 on the terminal/cmd for installing llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index==0.10.32\n",
      "  Obtaining dependency information for llama-index==0.10.32 from https://files.pythonhosted.org/packages/23/11/13a3bf9651ab6ef8423c3b2f44a45dc3d5a7df7deb17a33af9b4c215582b/llama_index-0.10.32-py3-none-any.whl.metadata\n",
      "  Downloading llama_index-0.10.32-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index==0.10.32) (0.2.9)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index==0.10.32) (0.1.13)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.32 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index==0.10.32) (0.10.68.post1)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index==0.10.32) (0.1.11)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index==0.10.32)\n",
      "  Obtaining dependency information for llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 from https://files.pythonhosted.org/packages/ef/7a/07f3be0a5a535382ca528b9f6b62316b43680396156ae3f799aec3577ebb/llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index==0.10.32) (0.9.48.post3)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index==0.10.32) (0.1.31)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index==0.10.32) (0.1.9)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index==0.10.32) (0.1.7)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index==0.10.32) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index==0.10.32) (0.1.33)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index==0.10.32) (0.1.6)\n",
      "Requirement already satisfied: openai>=1.14.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.32) (1.42.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2024.6.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (3.1)\n",
      "Requirement already satisfied: nltk!=3.9,>=3.8.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.24.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.5.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (9.4.0)\n",
      "Requirement already satisfied: pydantic<3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.14.1)\n",
      "Collecting llamaindex-py-client<0.2.0,>=0.1.19 (from llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2->llama-index==0.10.32)\n",
      "  Obtaining dependency information for llamaindex-py-client<0.2.0,>=0.1.19 from https://files.pythonhosted.org/packages/5e/9c/a1a3086f023a8957ebd527c98d9356b6dd9409edef827ffdeee484f47abf/llamaindex_py_client-0.1.19-py3-none-any.whl.metadata\n",
      "  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl.metadata (760 bytes)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.32) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.32) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.32) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.4.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.32) (0.4.9)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.8.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.32) (2.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\creat\\anaconda3\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\creat\\anaconda3\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2022.7.9)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.32) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.32) (0.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (0.4.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (3.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2022.7)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (23.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.16.0)\n",
      "Downloading llama_index-0.10.32-py3-none-any.whl (6.9 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n",
      "Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
      "   ---------------------------------------- 0.0/141.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 141.9/141.9 kB 8.8 MB/s eta 0:00:00\n",
      "Installing collected packages: llamaindex-py-client, llama-index-indices-managed-llama-cloud, llama-index\n",
      "  Attempting uninstall: llama-index-indices-managed-llama-cloud\n",
      "    Found existing installation: llama-index-indices-managed-llama-cloud 0.2.7\n",
      "    Uninstalling llama-index-indices-managed-llama-cloud-0.2.7:\n",
      "      Successfully uninstalled llama-index-indices-managed-llama-cloud-0.2.7\n",
      "  Attempting uninstall: llama-index\n",
      "    Found existing installation: llama-index 0.10.68\n",
      "    Uninstalling llama-index-0.10.68:\n",
      "      Successfully uninstalled llama-index-0.10.68\n",
      "Successfully installed llama-index-0.10.32 llama-index-indices-managed-llama-cloud-0.1.6 llamaindex-py-client-0.1.19\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting llama-index-core==0.10.32\n",
      "  Obtaining dependency information for llama-index-core==0.10.32 from https://files.pythonhosted.org/packages/2a/02/2e061de9e2dd7e0e9b987eab83f0cfafaf57dd5f8de3f60f5f02ef4d969d/llama_index_core-0.10.32-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_core-0.10.32-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (2024.6.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (0.1.19)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (3.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (1.24.3)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (1.42.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (1.5.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (9.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core==0.10.32) (1.14.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.32) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.32) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.32) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.32) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.32) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.32) (1.8.1)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.32) (2.8.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.32) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.32) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.32) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.32) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core==0.10.32) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.32) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\creat\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.32) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\creat\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.32) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.32) (2022.7.9)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from openai>=1.1.0->llama-index-core==0.10.32) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from openai>=1.1.0->llama-index-core==0.10.32) (0.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core==0.10.32) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core==0.10.32) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.32) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core==0.10.32) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.32) (0.4.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core==0.10.32) (3.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pandas->llama-index-core==0.10.32) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pandas->llama-index-core==0.10.32) (2022.7)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.32) (23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.32) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core==0.10.32) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->llama-index-core==0.10.32) (1.16.0)\n",
      "Downloading llama_index_core-0.10.32-py3-none-any.whl (15.4 MB)\n",
      "   ---------------------------------------- 0.0/15.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/15.4 MB 3.6 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.4/15.4 MB 5.3 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.1/15.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.7/15.4 MB 15.7 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.7/15.4 MB 17.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.8/15.4 MB 18.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.8/15.4 MB 16.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.2/15.4 MB 18.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.3/15.4 MB 16.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.4/15.4 MB 17.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.2/15.4 MB 17.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.1/15.4 MB 17.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.5/15.4 MB 17.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.9/15.4 MB 17.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.0/15.4 MB 15.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.4/15.4 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.7/15.4 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.0/15.4 MB 14.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.4/15.4 MB 14.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.7/15.4 MB 14.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.4/15.4 MB 12.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.8/15.4 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.3/15.4 MB 11.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.6/15.4 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.2/15.4 MB 10.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.7/15.4 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.1/15.4 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.4/15.4 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.4/15.4 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.4/15.4 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.4/15.4 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.4/15.4 MB 8.5 MB/s eta 0:00:00\n",
      "Installing collected packages: llama-index-core\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.10.68.post1\n",
      "    Uninstalling llama-index-core-0.10.68.post1:\n",
      "      Successfully uninstalled llama-index-core-0.10.68.post1\n",
      "Successfully installed llama-index-core-0.10.32\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-agent-openai 0.2.9 requires llama-index-core<0.11.0,>=0.10.41, but you have llama-index-core 0.10.32 which is incompatible.\n",
      "llama-index-llms-openai 0.1.31 requires llama-index-core<0.11.0,>=0.10.57, but you have llama-index-core 0.10.32 which is incompatible.\n",
      "llama-index-program-openai 0.1.7 requires llama-index-core<0.11.0,>=0.10.57, but you have llama-index-core 0.10.32 which is incompatible.\n",
      "llama-index-readers-file 0.1.33 requires llama-index-core<0.11.0,>=0.10.37.post1, but you have llama-index-core 0.10.32 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-llms-ollama==0.1.2Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for llama-index-llms-ollama==0.1.2 from https://files.pythonhosted.org/packages/dd/52/1e59f570238cf0594f1400cb8477e0d6712d546912a41669a72416a66ee1/llama_index_llms_ollama-0.1.2-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_llms_ollama-0.1.2-py3-none-any.whl.metadata (636 bytes)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-llms-ollama==0.1.2) (0.10.32)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (2024.6.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (0.1.19)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (3.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (1.24.3)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (1.42.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (1.5.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (9.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (1.14.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (1.8.1)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (2.8.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\creat\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\creat\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (2022.7.9)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (0.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (0.4.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (3.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (2022.7)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-ollama==0.1.2) (1.16.0)\n",
      "Downloading llama_index_llms_ollama-0.1.2-py3-none-any.whl (3.2 kB)\n",
      "Installing collected packages: llama-index-llms-ollama\n",
      "Successfully installed llama-index-llms-ollama-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "awswrangler 3.4.0 requires packaging<24.0,>=21.1, but you have packaging 24.1 which is incompatible.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\n",
      "sqlalchemy-mate 1.4.28.4 requires sqlalchemy<2.0.0,>=1.4.1, but you have sqlalchemy 2.0.32 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-readers-web==0.1.10\n",
      "  Obtaining dependency information for llama-index-readers-web==0.1.10 from https://files.pythonhosted.org/packages/3d/07/e7ccdb1fd0ceecf0b5a87fd200391ac5f13ea0df30f47c7c4976b4091b67/llama_index_readers_web-0.1.10-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_readers_web-0.1.10-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-readers-web==0.1.10) (3.10.5)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-readers-web==0.1.10) (4.12.3)\n",
      "Collecting chromedriver-autoinstaller<0.7.0,>=0.6.3 (from llama-index-readers-web==0.1.10)\n",
      "  Obtaining dependency information for chromedriver-autoinstaller<0.7.0,>=0.6.3 from https://files.pythonhosted.org/packages/a5/b5/36f0b0add145c371b5282e881a687601899f2d27fae5d0595bc02026b67c/chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata\n",
      "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting html2text<2021.0.0,>=2020.1.16 (from llama-index-readers-web==0.1.10)\n",
      "  Obtaining dependency information for html2text<2021.0.0,>=2020.1.16 from https://files.pythonhosted.org/packages/ae/88/14655f727f66b3e3199f4467bafcc88283e6c31b562686bf606264e09181/html2text-2020.1.16-py3-none-any.whl.metadata\n",
      "  Downloading html2text-2020.1.16-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-readers-web==0.1.10) (0.10.32)\n",
      "Collecting newspaper3k<0.3.0,>=0.2.8 (from llama-index-readers-web==0.1.10)\n",
      "  Obtaining dependency information for newspaper3k<0.3.0,>=0.2.8 from https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl.metadata\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting playwright<2.0,>=1.30 (from llama-index-readers-web==0.1.10)\n",
      "  Obtaining dependency information for playwright<2.0,>=1.30 from https://files.pythonhosted.org/packages/ba/27/b5f21695ee2ea32fdf826e531066e5633e1056171e217bac3daeefa46017/playwright-1.46.0-py3-none-win_amd64.whl.metadata\n",
      "  Downloading playwright-1.46.0-py3-none-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-readers-web==0.1.10) (2.31.0)\n",
      "Requirement already satisfied: selenium<5.0.0,>=4.17.2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-readers-web==0.1.10) (4.23.1)\n",
      "Requirement already satisfied: urllib3>=1.1.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-readers-web==0.1.10) (1.26.16)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web==0.1.10) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web==0.1.10) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web==0.1.10) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web==0.1.10) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web==0.1.10) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web==0.1.10) (1.8.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-web==0.1.10) (2.4)\n",
      "Collecting packaging>=23.1 (from chromedriver-autoinstaller<0.7.0,>=0.6.3->llama-index-readers-web==0.1.10)\n",
      "  Obtaining dependency information for packaging>=23.1 from https://files.pythonhosted.org/packages/08/aa/cc0199a5f0ad350994d660967a8efb233fe0416e4639146c089643407ce6/packaging-24.1-py3-none-any.whl.metadata\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (2.0.32)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (2024.6.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (0.1.19)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (3.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (1.24.3)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (1.42.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (1.5.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (9.4.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (1.14.1)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.10) (1.1.0)\n",
      "Requirement already satisfied: lxml>=3.6.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.10) (4.9.2)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.10)\n",
      "  Obtaining dependency information for feedparser>=5.2.1 from https://files.pythonhosted.org/packages/7c/d4/8c31aad9cc18f451c49f7f9cfb5799dadffc88177f7917bc90a66459b1d7/feedparser-6.0.11-py3-none-any.whl.metadata\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.10) (3.2.0)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.10)\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting jieba3k>=0.35.1 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.10)\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
      "     ---------------------------------------- 0.0/7.4 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.5/7.4 MB 14.9 MB/s eta 0:00:01\n",
      "     ----- ---------------------------------- 1.1/7.4 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 1.9/7.4 MB 13.2 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 2.7/7.4 MB 15.9 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 3.9/7.4 MB 17.6 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 4.5/7.4 MB 17.8 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 5.5/7.4 MB 17.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 6.2/7.4 MB 18.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 7.1/7.4 MB 18.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.4/7.4 MB 17.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.4/7.4 MB 17.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.4/7.4 MB 14.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.10) (2.8.2)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.10)\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting greenlet==3.0.3 (from playwright<2.0,>=1.30->llama-index-readers-web==0.1.10)\n",
      "  Obtaining dependency information for greenlet==3.0.3 from https://files.pythonhosted.org/packages/47/79/26d54d7d700ef65b689fc2665a40846d13e834da0486674a8d4f0f371a47/greenlet-3.0.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading greenlet-3.0.3-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting pyee==11.1.0 (from playwright<2.0,>=1.30->llama-index-readers-web==0.1.10)\n",
      "  Obtaining dependency information for pyee==11.1.0 from https://files.pythonhosted.org/packages/16/cc/5cea8a0a0d3deb90b5a0d39ad1a6a1ccaa40a9ea86d793eb8a49d32a6ed0/pyee-11.1.0-py3-none-any.whl.metadata\n",
      "  Downloading pyee-11.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.31.0->llama-index-readers-web==0.1.10) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.31.0->llama-index-readers-web==0.1.10) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.31.0->llama-index-readers-web==0.1.10) (2023.7.22)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from selenium<5.0.0,>=4.17.2->llama-index-readers-web==0.1.10) (0.26.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from selenium<5.0.0,>=4.17.2->llama-index-readers-web==0.1.10) (0.11.1)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from selenium<5.0.0,>=4.17.2->llama-index-readers-web==0.1.10) (1.8.0)\n",
      "Requirement already satisfied: six in c:\\users\\creat\\anaconda3\\lib\\site-packages (from feedfinder2>=0.0.4->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.10) (1.16.0)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.10)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (2.8.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\creat\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\creat\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (2022.7.9)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (0.5.0)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.10) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web==0.1.10) (3.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (0.4.6)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\creat\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web==0.1.10) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\creat\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web==0.1.10) (1.3.0.post0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web==0.1.10) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium<5.0.0,>=4.17.2->llama-index-readers-web==0.1.10) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (0.4.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from urllib3>=1.1.0->llama-index-readers-web==0.1.10) (1.7.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (3.22.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (2022.7)\n",
      "Requirement already satisfied: pycparser in c:\\users\\creat\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web==0.1.10) (2.21)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-web==0.1.10) (2.20.1)\n",
      "Downloading llama_index_readers_web-0.1.10-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.7/64.7 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
      "Using cached html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
      "Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "   ---------------------------------------- 0.0/211.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 211.1/211.1 kB ? eta 0:00:00\n",
      "Downloading playwright-1.46.0-py3-none-win_amd64.whl (29.8 MB)\n",
      "   ---------------------------------------- 0.0/29.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.4/29.8 MB 29.2 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 2.3/29.8 MB 20.8 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 2.7/29.8 MB 17.3 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 3.5/29.8 MB 15.8 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 4.0/29.8 MB 14.8 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 4.4/29.8 MB 14.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 4.9/29.8 MB 13.6 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 5.4/29.8 MB 13.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 6.5/29.8 MB 13.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 7.1/29.8 MB 13.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 8.1/29.8 MB 14.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 9.0/29.8 MB 14.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 10.5/29.8 MB 14.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 11.3/29.8 MB 14.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 12.3/29.8 MB 14.6 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 13.2/29.8 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 13.8/29.8 MB 16.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 14.3/29.8 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 14.8/29.8 MB 15.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 15.2/29.8 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 15.7/29.8 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 16.3/29.8 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 16.8/29.8 MB 15.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 17.3/29.8 MB 14.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 17.8/29.8 MB 14.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 18.3/29.8 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 18.8/29.8 MB 13.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 19.1/29.8 MB 13.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 19.8/29.8 MB 12.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 20.2/29.8 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 20.9/29.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 21.5/29.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 22.2/29.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 22.8/29.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 23.5/29.8 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 24.1/29.8 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 24.8/29.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 25.4/29.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 26.1/29.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 26.6/29.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 27.2/29.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 28.0/29.8 MB 12.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 28.6/29.8 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.4/29.8 MB 13.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.8/29.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 29.8/29.8 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.0.3-cp311-cp311-win_amd64.whl (292 kB)\n",
      "   ---------------------------------------- 0.0/292.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 292.8/292.8 kB 17.7 MB/s eta 0:00:00\n",
      "Downloading pyee-11.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "   ---------------------------------------- 0.0/81.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 81.3/81.3 kB 4.4 MB/s eta 0:00:00\n",
      "Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
      "  Building wheel for tinysegmenter (setup.py): started\n",
      "  Building wheel for tinysegmenter (setup.py): finished with status 'done'\n",
      "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13566 sha256=64ab818e7d4b19622da592ee8dbbf8ce431e2edc6e2f705bd6d7b4e70c78ff1c\n",
      "  Stored in directory: c:\\users\\creat\\appdata\\local\\pip\\cache\\wheels\\fc\\ab\\f8\\cce3a9ae6d828bd346be695f7ff54612cd22b7cbd7208d68f3\n",
      "  Building wheel for feedfinder2 (setup.py): started\n",
      "  Building wheel for feedfinder2 (setup.py): finished with status 'done'\n",
      "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3358 sha256=66ac5c79c0aee403c1cad7911ef862d487795abc47f407e86dde0271c33897a5\n",
      "  Stored in directory: c:\\users\\creat\\appdata\\local\\pip\\cache\\wheels\\80\\d5\\72\\9cd9eccc819636436c6a6e59c22a0fb1ec167beef141f56491\n",
      "  Building wheel for jieba3k (setup.py): started\n",
      "  Building wheel for jieba3k (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398388 sha256=f004a706ab259c92e814bdecd4c75ec54b14b5a11c70e5ac91b7bdbd13c7172f\n",
      "  Stored in directory: c:\\users\\creat\\appdata\\local\\pip\\cache\\wheels\\3a\\a1\\46\\8e68055c1713f9c4598774c15ad0541f26d5425ee7423b6493\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6061 sha256=82dbcf198af83c19ca01f18f101587a976d16019185d4808b5a32d10f482371d\n",
      "  Stored in directory: c:\\users\\creat\\appdata\\local\\pip\\cache\\wheels\\3b\\25\\2a\\105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
      "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
      "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, pyee, packaging, html2text, greenlet, feedparser, playwright, feedfinder2, chromedriver-autoinstaller, newspaper3k, llama-index-readers-web\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.0\n",
      "    Uninstalling packaging-23.0:\n",
      "      Successfully uninstalled packaging-23.0\n",
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 2.0.1\n",
      "    Uninstalling greenlet-2.0.1:\n",
      "      Successfully uninstalled greenlet-2.0.1\n",
      "Successfully installed chromedriver-autoinstaller-0.6.4 feedfinder2-0.0.4 feedparser-6.0.11 greenlet-3.0.3 html2text-2020.1.16 jieba3k-0.35.1 llama-index-readers-web-0.1.10 newspaper3k-0.2.8 packaging-24.1 playwright-1.46.0 pyee-11.1.0 sgmllib3k-1.0.0 tinysegmenter-0.3\n",
      "Collecting llama-index-embeddings-ollama==0.1.2\n",
      "  Obtaining dependency information for llama-index-embeddings-ollama==0.1.2 from https://files.pythonhosted.org/packages/a4/79/783a2461c68bd8bebe3b29be52276b24e4a89de84be40c2afa2da48554aa/llama_index_embeddings_ollama-0.1.2-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_embeddings_ollama-0.1.2-py3-none-any.whl.metadata (654 bytes)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-embeddings-ollama==0.1.2) (0.10.32)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (2024.6.1)\n",
      "Requirement already satisfied: httpx in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (0.1.19)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (3.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (1.24.3)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (1.42.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (1.5.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (9.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (1.14.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (1.8.1)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (2.8.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\creat\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\creat\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (2022.7.9)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (0.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\creat\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (0.4.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (3.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (2022.7)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\creat\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-ollama==0.1.2) (1.16.0)\n",
      "Downloading llama_index_embeddings_ollama-0.1.2-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: llama-index-embeddings-ollama\n",
      "Successfully installed llama-index-embeddings-ollama-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Retrieval augmented generation \n",
    "\n",
    "%pip install llama-index==0.10.32  \n",
    "%pip install llama-index-core==0.10.32  \n",
    "%pip install llama-index-llms-ollama==0.1.2 \n",
    "%pip install llama-index-readers-web==0.1.10  \n",
    "%pip install llama-index-embeddings-ollama==0.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from llama_cpp import Llama\n",
    "# from llama_index import SimpleDirectoryReader, GPTSimpleVectorIndex, LLMPredictor, ServiceContext\n",
    "# from llama_index.node_parser import SimpleNodeParser\n",
    "# from llama_index.langchain_helpers.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from llama_index.prompts.prompts import SimpleInputPrompt\n",
    "# from llama_index.schema import Document\n",
    "# from llama_index.vector_stores import SimpleVectorStore\n",
    "\n",
    "# # Step 1: Load the Llama model\n",
    "# model_path = \"path_to_your_llama_model\"  # Adjust this path accordingly\n",
    "# llm = Llama(model_path=model_path)\n",
    "\n",
    "# # Step 2: Create a document store (can load your documents from a directory)\n",
    "# documents = [\n",
    "#     Document(text=\"Document 1 content here.\"),\n",
    "#     Document(text=\"Document 2 content here.\"),\n",
    "#     Document(text=\"Document 3 content here.\"),\n",
    "#     # Add more documents as needed\n",
    "# ]\n",
    "\n",
    "# # Step 3: Setup the Service Context for the LLM Predictor\n",
    "# llm_predictor = LLMPredictor(llm=llm)\n",
    "# service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n",
    "\n",
    "# # Step 4: Create an index (e.g., using GPTSimpleVectorIndex)\n",
    "# index = GPTSimpleVectorIndex.from_documents(documents, service_context=service_context)\n",
    "\n",
    "# # Step 5: Define a function to query the model and get a response\n",
    "# def query_model(query):\n",
    "#     response = index.query(query)\n",
    "#     return response.response\n",
    "\n",
    "# # Example usage:\n",
    "# query = \"What is the content of the first document?\"\n",
    "# response = query_model(query)\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "\n",
    "\n",
    "documents = SimpleWebPageReader(html_to_text=True).load_data(\n",
    "    [\"https://ai.meta.com/blog/meta-llama-3/\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='https://ai.meta.com/blog/meta-llama-3/', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='![Meta](https://scontent.fdel1-5.fna.fbcdn.net/v/t39.8562-6/252294889_575082167077436_6034106545912333281_n.svg/meta-\\nlogo-\\nprimary_standardsize.svg?_nc_cat=108&ccb=1-7&_nc_sid=e280be&_nc_ohc=MBLMQMqFj5QQ7kNvgET3B2Z&_nc_ht=scontent.fdel1-5.fna&oh=00_AYDK2EgQPQary57mAYd3iXdqOTfJoAUV9SRu2I0Oy1VuXw&oe=66DBA2F9)\\n\\n* Our approach\\n* Research\\n* Product experiences\\n* [Llama](https://llama.meta.com/)\\n* [Blog](/blog/)\\n* [Try Meta AI](https://www.meta.ai/?utm_source=ai_meta_site&utm_medium=web&utm_content=AI_nav&utm_campaign=April_moment)\\n* [](/)\\n\\nLarge Language Model\\n\\nIntroducing Meta Llama 3: The most capable openly available LLM to date\\n\\nApril 18, 2024\\n\\n  \\n\\nTakeaways:\\n\\nRECOMMENDED READS\\n\\n  * [5 Steps to Getting Started with Llama 2](https://ai.meta.com/blog/5-steps-to-getting-started-with-llama-2/)\\n  * [The Llama Ecosystem: Past, Present, and Future](https://ai.meta.com/blog/llama-2-updates-connect-2023/)\\n  * [Introducing Code Llama, a state-of-the-art large language model for coding](https://ai.meta.com/blog/code-llama-large-language-model-coding/)\\n  * [Meta and Microsoft Introduce the Next Generation of Llama](https://ai.meta.com/blog/llama-2/)\\n\\n  \\n\\n  * Today, we’re introducing Meta Llama 3, the next generation of our state-of-the-art open source large language model.\\n  * Llama 3 models will soon be available on AWS, Databricks, Google Cloud, Hugging Face, Kaggle, IBM WatsonX, Microsoft Azure, NVIDIA NIM, and Snowflake, and with support from hardware platforms offered by AMD, AWS, Dell, Intel, NVIDIA, and Qualcomm.\\n  * We’re dedicated to developing Llama 3 in a responsible way, and we’re offering various resources to help others use it responsibly as well. This includes introducing new trust and safety tools with Llama Guard 2, Code Shield, and CyberSec Eval 2.\\n  * In the coming months, we expect to introduce new capabilities, longer context windows, additional model sizes, and enhanced performance, and we’ll share the Llama 3 research paper.\\n  * Meta AI, built with Llama 3 technology, is now one of the world’s leading AI assistants that can boost your intelligence and lighten your load—helping you learn, get things done, create content, and connect to make the most out of every moment. You can try Meta AI [_here_](https://meta.ai/).\\n\\n  \\n\\nToday, we’re excited to share the first two models of the next generation of\\nLlama, Meta Llama 3, available for broad use. This release features pretrained\\nand instruction-fine-tuned language models with 8B and 70B parameters that can\\nsupport a broad range of use cases. This next generation of Llama demonstrates\\nstate-of-the-art performance on a wide range of industry benchmarks and offers\\nnew capabilities, including improved reasoning. We believe these are the best\\nopen source models of their class, period. In support of our longstanding open\\napproach, we’re putting Llama 3 in the hands of the community. We want to\\nkickstart the next wave of innovation in AI across the stack—from applications\\nto developer tools to evals to inference optimizations and more. We can’t wait\\nto see what you build and look forward to your feedback.\\n\\nOur goals for Llama 3\\n\\n  \\n\\nWith Llama 3, we set out to build the best open models that are on par with\\nthe best proprietary models available today. We wanted to address developer\\nfeedback to increase the overall helpfulness of Llama 3 and are doing so while\\ncontinuing to play a leading role on responsible use and deployment of LLMs.\\nWe are embracing the open source ethos of releasing early and often to enable\\nthe community to get access to these models while they are still in\\ndevelopment. The text-based models we are releasing today are the first in the\\nLlama 3 collection of models. Our goal in the near future is to make Llama 3\\nmultilingual and multimodal, have longer context, and continue to improve\\noverall performance across core LLM capabilities such as reasoning and coding.\\n\\nState-of-the-art performance\\n\\nOur new 8B and 70B parameter Llama 3 models are a major leap over Llama 2 and\\nestablish a new state-of-the-art for LLM models at those scales. Thanks to\\nimprovements in pretraining and post-training, our pretrained and instruction-\\nfine-tuned models are the best models existing today at the 8B and 70B\\nparameter scale. Improvements in our post-training procedures substantially\\nreduced false refusal rates, improved alignment, and increased diversity in\\nmodel responses. We also saw greatly improved capabilities like reasoning,\\ncode generation, and instruction following making Llama 3 more steerable.\\n\\n  \\n\\n![](https://scontent.fdel1-6.fna.fbcdn.net/v/t39.2365-6/438037375_405784438908376_6082258861354187544_n.png?_nc_cat=106&ccb=1-7&_nc_sid=e280be&_nc_ohc=fuHJhREW_ygQ7kNvgH8ArKg&_nc_ht=scontent.fdel1-6.fna&oh=00_AYAIHCzR5Mt0eqKzDQBrVRxwuoHvwoN_g96xPdBoIqgblQ&oe=66F0074A)\\n\\n*Please see [_evaluation details_](https://github.com/meta-llama/llama3/blob/main/eval_details.md) for setting and parameters with which these evaluations are calculated.\\n\\n  \\n\\nIn the development of Llama 3, we looked at model performance on standard\\nbenchmarks and also sought to optimize for performance for real-world\\nscenarios. To this end, we developed a new high-quality human evaluation set.\\nThis evaluation set contains 1,800 prompts that cover 12 key use cases: asking\\nfor advice, brainstorming, classification, closed question answering, coding,\\ncreative writing, extraction, inhabiting a character/persona, open question\\nanswering, reasoning, rewriting, and summarization. To prevent accidental\\noverfitting of our models on this evaluation set, even our own modeling teams\\ndo not have access to it. The chart below shows aggregated results of our\\nhuman evaluations across of these categories and prompts against Claude\\nSonnet, Mistral Medium, and GPT-3.5.\\n\\n  \\n\\n![](https://scontent.fdel1-3.fna.fbcdn.net/v/t39.2365-6/438998263_1368970367138244_7396600838045603809_n.png?_nc_cat=111&ccb=1-7&_nc_sid=e280be&_nc_ohc=ezE3-gEA9LoQ7kNvgGQAfrD&_nc_ht=scontent.fdel1-3.fna&oh=00_AYB-\\nFN1dfUPRcc34Pow0U_su61IeRWdpEmkMoI-LCKw0Mw&oe=66F024CF)\\n\\nPreference rankings by human annotators based on this evaluation set highlight\\nthe strong performance of our 70B instruction-following model compared to\\ncompeting models of comparable size in real-world scenarios.\\n\\nOur pretrained model also establishes a new state-of-the-art for LLM models at\\nthose scales.\\n\\n![](https://scontent.fdel1-6.fna.fbcdn.net/v/t39.2365-6/439014085_432870519293677_8138616034495713484_n.png?_nc_cat=109&ccb=1-7&_nc_sid=e280be&_nc_ohc=XJxi39plbxIQ7kNvgG5AZrG&_nc_ht=scontent.fdel1-6.fna&oh=00_AYBlcN51uePt_gVB9UYgTdTKJ_rsj_wsZVIP0J-zF4AsjA&oe=66F00E74)\\n\\n*Please see [_evaluation details_](https://github.com/meta-llama/llama3/blob/main/eval_details.md) for setting and parameters with which these evaluations are calculated.\\n\\n  \\n\\nTo develop a great language model, we believe it’s important to innovate,\\nscale, and optimize for simplicity. We adopted this design philosophy\\nthroughout the Llama 3 project with a focus on four key ingredients: the model\\narchitecture, the pretraining data, scaling up pretraining, and instruction\\nfine-tuning.\\n\\nModel architecture\\n\\nIn line with our design philosophy, we opted for a relatively standard\\ndecoder-only transformer architecture in Llama 3. Compared to Llama 2, we made\\nseveral key improvements. Llama 3 uses a tokenizer with a vocabulary of 128K\\ntokens that encodes language much more efficiently, which leads to\\nsubstantially improved model performance. To improve the inference efficiency\\nof Llama 3 models, we’ve adopted grouped query attention (GQA) across both the\\n8B and 70B sizes. We trained the models on sequences of 8,192 tokens, using a\\nmask to ensure self-attention does not cross document boundaries.\\n\\nTraining data\\n\\nTo train the best language model, the curation of a large, high-quality\\ntraining dataset is paramount. In line with our design principles, we invested\\nheavily in pretraining data. Llama 3 is pretrained on over 15T tokens that\\nwere all collected from publicly available sources. Our training dataset is\\nseven times larger than that used for Llama 2, and it includes four times more\\ncode. To prepare for upcoming multilingual use cases, over 5% of the Llama 3\\npretraining dataset consists of high-quality non-English data that covers over\\n30 languages. However, we do not expect the same level of performance in these\\nlanguages as in English.\\n\\nTo ensure Llama 3 is trained on data of the highest quality, we developed a\\nseries of data-filtering pipelines. These pipelines include using heuristic\\nfilters, NSFW filters, semantic deduplication approaches, and text classifiers\\nto predict data quality. We found that previous generations of Llama are\\nsurprisingly good at identifying high-quality data, hence we used Llama 2 to\\ngenerate the training data for the text-quality classifiers that are powering\\nLlama 3.\\n\\nWe also performed extensive experiments to evaluate the best ways of mixing\\ndata from different sources in our final pretraining dataset. These\\nexperiments enabled us to select a data mix that ensures that Llama 3 performs\\nwell across use cases including trivia questions, STEM, coding, historical\\nknowledge, _etc._\\n\\nScaling up pretraining\\n\\nTo effectively leverage our pretraining data in Llama 3 models, we put\\nsubstantial effort into scaling up pretraining. Specifically, we have\\ndeveloped a series of detailed scaling laws for downstream benchmark\\nevaluations. These scaling laws enable us to select an optimal data mix and to\\nmake informed decisions on how to best use our training compute. Importantly,\\nscaling laws allow us to predict the performance of our largest models on key\\ntasks (for example, code generation as evaluated on the HumanEval\\nbenchmark—see above) before we actually train the models. This helps us ensure\\nstrong performance of our final models across a variety of use cases and\\ncapabilities.\\n\\nWe made several new observations on scaling behavior during the development of\\nLlama 3. For example, while the Chinchilla-optimal amount of training compute\\nfor an 8B parameter model corresponds to ~200B tokens, we found that model\\nperformance continues to improve even after the model is trained on two orders\\nof magnitude more data. Both our 8B and 70B parameter models continued to\\nimprove log-linearly after we trained them on up to 15T tokens. Larger models\\ncan match the performance of these smaller models with less training compute,\\nbut smaller models are generally preferred because they are much more\\nefficient during inference.\\n\\nTo train our largest Llama 3 models, we combined three types of\\nparallelization: data parallelization, model parallelization, and pipeline\\nparallelization. Our most efficient implementation achieves a compute\\nutilization of over 400 TFLOPS per GPU when trained on 16K GPUs\\nsimultaneously. We performed training runs on two custom-built [_24K GPU\\nclusters_](https://engineering.fb.com/2024/03/12/data-center-\\nengineering/building-metas-genai-infrastructure/). To maximize GPU uptime, we\\ndeveloped an advanced new training stack that automates error detection,\\nhandling, and maintenance. We also greatly improved our hardware reliability\\nand detection mechanisms for silent data corruption, and we developed new\\nscalable storage systems that reduce overheads of checkpointing and rollback.\\nThose improvements resulted in an overall effective training time of more than\\n95%. Combined, these improvements increased the efficiency of Llama 3 training\\nby ~three times compared to Llama 2.\\n\\nInstruction fine-tuning\\n\\nTo fully unlock the potential of our pretrained models in chat use cases, we\\ninnovated on our approach to instruction-tuning as well. Our approach to post-\\ntraining is a combination of supervised fine-tuning (SFT), rejection sampling,\\nproximal policy optimization (PPO), and direct preference optimization (DPO).\\nThe quality of the prompts that are used in SFT and the preference rankings\\nthat are used in PPO and DPO has an outsized influence on the performance of\\naligned models. Some of our biggest improvements in model quality came from\\ncarefully curating this data and performing multiple rounds of quality\\nassurance on annotations provided by human annotators.\\n\\nLearning from preference rankings via PPO and DPO also greatly improved the\\nperformance of Llama 3 on reasoning and coding tasks. We found that if you ask\\na model a reasoning question that it struggles to answer, the model will\\nsometimes produce the right reasoning trace: The model knows how to produce\\nthe right answer, but it does not know how to select it. Training on\\npreference rankings enables the model to learn how to select it.\\n\\nBuilding with Llama 3\\n\\nOur vision is to enable developers to customize Llama 3 to support relevant\\nuse cases and to make it easier to adopt best practices and improve the open\\necosystem. With this release, we’re providing new trust and safety tools\\nincluding updated [_components_](https://github.com/meta-llama/PurpleLlama)\\nwith both Llama Guard 2 and Cybersec Eval 2, and the introduction of Code\\nShield—an inference time guardrail for filtering insecure code produced by\\nLLMs.\\n\\nWe’ve also co-developed Llama 3 with\\n[_torchtune_](https://github.com/pytorch/torchtune), the new PyTorch-native\\nlibrary for easily authoring, fine-tuning, and experimenting with LLMs.\\ntorchtune provides memory efficient and hackable training recipes written\\nentirely in PyTorch. The library is integrated with popular platforms such as\\nHugging Face, Weights & Biases, and EleutherAI and even supports Executorch\\nfor enabling efficient inference to be run on a wide variety of mobile and\\nedge devices. For everything from prompt engineering to using Llama 3 with\\nLangChain we have a comprehensive [_getting started\\nguide_](https://llama.meta.com/get-started/) and takes you from downloading\\nLlama 3 all the way to deployment at scale within your generative AI\\napplication.\\n\\nA system-level approach to responsibility\\n\\nWe have designed Llama 3 models to be maximally helpful while ensuring an\\nindustry leading approach to responsibly deploying them. To achieve this, we\\nhave adopted [_a new, system-level approach_](https://ai.meta.com/blog/meta-\\nllama-3-meta-ai-responsibility/) to the responsible development and deployment\\nof Llama. We envision Llama models as part of a broader system that puts the\\ndeveloper in the driver’s seat. Llama models will serve as a foundational\\npiece of a system that developers design with their unique end goals in mind.\\n\\n![](https://scontent.fdel1-2.fna.fbcdn.net/v/t39.2365-6/438922663_1135166371264105_805978695964769385_n.png?_nc_cat=107&ccb=1-7&_nc_sid=e280be&_nc_ohc=8Koo9BaJvNgQ7kNvgErtUi5&_nc_ht=scontent.fdel1-2.fna&oh=00_AYC6dtt61qux4-JFQPAf32jUDdyqKpFk-\\nSHIDlUMrGHVJg&oe=66EFF51E)\\n\\nInstruction fine-tuning also plays a major role in ensuring the safety of our\\nmodels. Our instruction-fine-tuned models have been red-teamed (tested) for\\nsafety through internal and external efforts. \\u200b\\u200bOur red teaming approach\\nleverages human experts and automation methods to generate adversarial prompts\\nthat try to elicit problematic responses. For instance, we apply comprehensive\\ntesting to assess risks of misuse related to Chemical, Biological, Cyber\\nSecurity, and other risk areas. All of these efforts are iterative and used to\\ninform safety fine-tuning of the models being released. You can read more\\nabout our efforts in the [_model card_](https://github.com/meta-\\nllama/llama3/blob/main/MODEL_CARD.md).\\n\\nLlama Guard models are meant to be a foundation for prompt and response safety\\nand can easily be fine-tuned to create a new taxonomy depending on application\\nneeds. As a starting point, the new Llama Guard 2 uses the recently\\n[_announced_](https://mlcommons.org/2024/04/mlc-aisafety-v0-5-poc/) MLCommons\\ntaxonomy, in an effort to support the emergence of industry standards in this\\nimportant area. Additionally, CyberSecEval 2 expands on its predecessor by\\nadding measures of an LLM’s propensity to allow for abuse of its code\\ninterpreter, offensive cybersecurity capabilities, and susceptibility to\\nprompt injection attacks (learn more in [_our technical\\npaper_](https://ai.meta.com/research/publications/cyberseceval-2-a-wide-\\nranging-cybersecurity-evaluation-suite-for-large-language-models/)). Finally,\\nwe’re introducing Code Shield which adds support for inference-time filtering\\nof insecure code produced by LLMs. This offers mitigation of risks around\\ninsecure code suggestions, code interpreter abuse prevention, and secure\\ncommand execution.\\n\\nWith the speed at which the generative AI space is moving, we believe an open\\napproach is an important way to bring the ecosystem together and mitigate\\nthese potential harms. As part of that, we’re updating our [_Responsible Use\\nGuide_](https://llama.meta.com/responsible-use-guide) (RUG) that provides a\\ncomprehensive guide to responsible development with LLMs. As we outlined in\\nthe RUG, we recommend that all inputs and outputs be checked and filtered in\\naccordance with content guidelines appropriate to the application.\\nAdditionally, many cloud service providers offer content moderation APIs and\\nother tools for responsible deployment, and we encourage developers to also\\nconsider using these options.\\n\\nDeploying Llama 3 at scale\\n\\nLlama 3 will soon be available on all major platforms including cloud\\nproviders, model API providers, and much more. Llama 3 will be\\n[_everywhere_](https://llama.meta.com/get-started/).\\n\\nOur benchmarks show the tokenizer offers improved token efficiency, yielding\\nup to 15% fewer tokens compared to Llama 2. Also, Group Query Attention (GQA)\\nnow has been added to Llama 3 8B as well. As a result, we observed that\\ndespite the model having 1B more parameters compared to Llama 2 7B, the\\nimproved tokenizer efficiency and GQA contribute to maintaining the inference\\nefficiency on par with Llama 2 7B.\\n\\nFor examples of how to leverage all of these capabilities, check out [_Llama\\nRecipes_](https://github.com/meta-llama/llama-recipes) which contains all of\\nour open source code that can be leveraged for everything from fine-tuning to\\ndeployment to model evaluation.\\n\\nWhat’s next for Llama 3?\\n\\nThe Llama 3 8B and 70B models mark the beginning of what we plan to release\\nfor Llama 3. And there’s a lot more to come.\\n\\nOur largest models are over 400B parameters and, while these models are still\\ntraining, our team is excited about how they’re trending. Over the coming\\nmonths, we’ll release multiple models with new capabilities including\\nmultimodality, the ability to converse in multiple languages, a much longer\\ncontext window, and stronger overall capabilities. We will also publish a\\ndetailed research paper once we are done training Llama 3.\\n\\nTo give you a sneak preview for where these models are today as they continue\\ntraining, we thought we could share some snapshots of how our largest LLM\\nmodel is trending. Please note that this data is based on an early checkpoint\\nof Llama 3 that is still training and these capabilities are not supported as\\npart of the models released today.\\n\\n![](https://scontent.fdel1-4.fna.fbcdn.net/v/t39.2365-6/439015366_1603174683862748_5008894608826037916_n.png?_nc_cat=105&ccb=1-7&_nc_sid=e280be&_nc_ohc=ZtYHRI6zWg0Q7kNvgFe7uth&_nc_ht=scontent.fdel1-4.fna&oh=00_AYCKR5BCe2QOHh4j2Vmog8dOJiL1bHxknL87lX4iu__5ZQ&oe=66F0102A)\\n\\n*Please see [_evaluation details_](https://github.com/meta-llama/llama3/blob/main/eval_details.md) for setting and parameters with which these evaluations are calculated.\\n\\n  \\n\\nWe’re committed to the continued growth and development of an open AI\\necosystem for releasing our models responsibly. We have long believed that\\nopenness leads to better, safer products, faster innovation, and a healthier\\noverall market. This is good for Meta, and it is good for society. We’re\\ntaking a community-first approach with Llama 3, and starting today, these\\nmodels are available on the leading cloud, hosting, and hardware platforms\\nwith many more to come.\\n\\nTry Meta Llama 3 today\\n\\nWe’ve integrated our latest models into Meta AI, which we believe is the\\nworld’s leading AI assistant. It’s now built with Llama 3 technology and it’s\\navailable in more countries across our apps.\\n\\nYou can use Meta AI on Facebook, Instagram, WhatsApp, Messenger, and [_the\\nweb_](https://meta.ai/) to get things done, learn, create, and connect with\\nthe things that matter to you. You can read more about the Meta AI experience\\n[_here_](https://about.fb.com/news/2024/04/meta-ai-assistant-built-with-\\nllama-3/).\\n\\nVisit the[ _Llama 3 website_](https://llama.meta.com/llama3) to download the\\nmodels and reference the[ _Getting Started Guide_](https://llama.meta.com/get-\\nstarted/) for the latest list of all available platforms.\\n\\nYou’ll also soon be able to test multimodal Meta AI on our Ray-Ban Meta smart\\nglasses.\\n\\nAs always, we look forward to seeing all the amazing products and experiences\\nyou will build with Meta Llama 3.\\n\\n* * *\\n\\nShare:[](https://www.facebook.com/sharer/sharer.php?u=https://ai.meta.com/blog/meta-\\nllama-3/)[](https://www.twitter.com/share?url=https://ai.meta.com/blog/meta-\\nllama-3/)[](https://www.linkedin.com/sharing/share-\\noffsite?url=https://ai.meta.com/blog/meta-llama-3/)\\n\\n* * *\\n\\nOur latest updates delivered to your inbox\\n\\n[Subscribe](https://ai.facebook.com/subscribe/) to our newsletter to keep up\\nwith Meta AI news, events, research breakthroughs, and more.\\n\\nJoin us in the pursuit of what’s possible with AI.\\n\\n[See all open\\npositions](https://www.metacareers.com/jobs/?is_leadership=0&sub_teams%5B0%5D=Artificial+Intelligence&is_in_page=0&fbclid=IwAR0O8BF7opOj5gASJmwYVGalPPXTLu-6xrl9w00eC7Rarp2HQ9uEH8tERFw)\\n\\nRelated Posts\\n\\n![](https://scontent.fdel1-5.fna.fbcdn.net/v/t39.2365-6/338318848_238475658638014_6444534044370711549_n.gif?_nc_cat=108&ccb=1-7&_nc_sid=e280be&_nc_ohc=tUR4mBbFD5kQ7kNvgEUt-Z9&_nc_ht=scontent.fdel1-5.fna&oh=00_AYCJiKxlRmYI2KFXfI8SOy_TsgBBpWhwDZzuFbB1Uzfwbg&oe=66F01A69)\\n\\nComputer Vision\\n\\nIntroducing Segment Anything: Working toward the first foundation model for\\nimage segmentation\\n\\nApril 5, 2023\\n\\n[Read post](https://ai.meta.com/blog/segment-anything-foundation-model-image-\\nsegmentation/)\\n\\nFEATURED\\n\\n![](https://scontent.fdel1-7.fna.fbcdn.net/v/t39.2365-6/284099254_760295688673506_1047420741523524710_n.jpg?_nc_cat=103&ccb=1-7&_nc_sid=e280be&_nc_ohc=njIHsYLbO8gQ7kNvgHibqj6&_nc_ht=scontent.fdel1-7.fna&oh=00_AYCc1\\n--ahT1xu_UagRYvGMBkjqrWj8V1I56n0Yv9_Iv27g&oe=66F026F6)\\n\\nResearch\\n\\nMultiRay: Optimizing efficiency for large-scale AI models\\n\\nNovember 18, 2022\\n\\n[Read post](https://ai.meta.com/blog/multiray-large-scale-AI-models/)\\n\\nFEATURED\\n\\n![](https://scontent.fdel1-8.fna.fbcdn.net/v/t39.2365-6/334793505_583125787173687_542838236294006040_n.png?_nc_cat=100&ccb=1-7&_nc_sid=e280be&_nc_ohc=EtoGxP8ryZEQ7kNvgH9Aiqt&_nc_ht=scontent.fdel1-8.fna&oh=00_AYAk14Jru6q8TTaYmz9mn2vH33GHYgjPP4MxllG1bfq5Dw&oe=66F00244)\\n\\nML Applications\\n\\nMuAViC: The first audio-video speech translation benchmark\\n\\nMarch 8, 2023\\n\\n[Read post](https://ai.meta.com/blog/muavic-audio-visual-speech-translation-\\nbenchmark/)\\n\\n[Our approach](/about) __ __\\n\\n[About AI at Meta](/about)\\n\\n[ Responsibility](/responsible-ai)\\n\\n[People](/results/?content_types%5B0%5D=person&sort_by=random)\\n\\n[Careers](https://www.metacareers.com/jobs/?is_leadership=0&sub_teams\\\\[0\\\\]=Artificial%20Intelligence&is_in_page=0)\\n\\n[Research](/research) __ __\\n\\n[Infrastructure](/infrastructure)\\n\\n[ Resources](/resources)\\n\\n[Demos](https://aidemos.meta.com/)\\n\\nProduct experiences\\n\\n __ __\\n\\n[Meta AI](/meta-ai/)\\n\\n[ AI Studio](/ai-studio/)\\n\\n[Latest news](/blog) __ __\\n\\n[Blog](/blog)\\n\\n[ Newsletter](/subscribe)\\n\\nFoundational models\\n\\n __ __\\n\\n[Llama](https://llama.meta.com/)\\n\\n![](https://scontent.fdel1-7.fna.fbcdn.net/v/t39.2365-6/87524316_2677189655726266_6338721200264445952_n.svg?_nc_cat=103&ccb=1-7&_nc_sid=e280be&_nc_ohc=KccmCiFWmVkQ7kNvgE7SWa9&_nc_ht=scontent.fdel1-7.fna&oh=00_AYApWygGs8q06-5L1xwy2aKDVkmimTffmzOeIG3OJdDJqQ&oe=66F00CB8)\\n\\n[![](https://scontent.fdel1-8.fna.fbcdn.net/v/t39.8562-6/335682312_964107378293184_3093631164486164913_n.svg?_nc_cat=100&ccb=1-7&_nc_sid=e280be&_nc_ohc=erPJUFZABnAQ7kNvgGCpRUQ&_nc_ht=scontent.fdel1-8.fna&oh=00_AYBA750lwGLtnNcHfea2pV3n2jOeOtNA8CE_G8x4XaBnUA&oe=66DB9327)![](https://scontent.fdel1-8.fna.fbcdn.net/v/t39.8562-6/335682312_964107378293184_3093631164486164913_n.svg?_nc_cat=100&ccb=1-7&_nc_sid=e280be&_nc_ohc=erPJUFZABnAQ7kNvgGCpRUQ&_nc_ht=scontent.fdel1-8.fna&oh=00_AYBA750lwGLtnNcHfea2pV3n2jOeOtNA8CE_G8x4XaBnUA&oe=66DB9327)](https://www.facebook.com/aiatmeta/)\\n\\n[![](https://scontent.fdel1-7.fna.fbcdn.net/v/t39.8562-6/336009607_1870102080040414_6753977241281150924_n.svg?_nc_cat=103&ccb=1-7&_nc_sid=e280be&_nc_ohc=SNVlogX_i-\\nUQ7kNvgEfRlYO&_nc_ht=scontent.fdel1-7.fna&oh=00_AYBTiBa9jOXr_bzPnChCA5Z8aTiZBYTR8WTSFG0xuosb7g&oe=66DB8B62)![](https://scontent.fdel1-7.fna.fbcdn.net/v/t39.8562-6/336009607_1870102080040414_6753977241281150924_n.svg?_nc_cat=103&ccb=1-7&_nc_sid=e280be&_nc_ohc=SNVlogX_i-\\nUQ7kNvgEfRlYO&_nc_ht=scontent.fdel1-7.fna&oh=00_AYBTiBa9jOXr_bzPnChCA5Z8aTiZBYTR8WTSFG0xuosb7g&oe=66DB8B62)](https://twitter.com/aiatmeta/)\\n\\n[![](https://scontent.fdel1-6.fna.fbcdn.net/v/t39.8562-6/336289415_1541032296405649_2165099305308791297_n.svg?_nc_cat=109&ccb=1-7&_nc_sid=e280be&_nc_ohc=3SBqtvuqWDIQ7kNvgGZCiep&_nc_ht=scontent.fdel1-6.fna&oh=00_AYAIKEFIlfp_cDxMqPAtQGtNkCgWb5ryVGttMTJiLiiKsA&oe=66DBB73B)![](https://scontent.fdel1-6.fna.fbcdn.net/v/t39.8562-6/336289415_1541032296405649_2165099305308791297_n.svg?_nc_cat=109&ccb=1-7&_nc_sid=e280be&_nc_ohc=3SBqtvuqWDIQ7kNvgGZCiep&_nc_ht=scontent.fdel1-6.fna&oh=00_AYAIKEFIlfp_cDxMqPAtQGtNkCgWb5ryVGttMTJiLiiKsA&oe=66DBB73B)](https://www.linkedin.com/showcase/aiatmeta)\\n\\n[![](https://scontent.fdel1-5.fna.fbcdn.net/v/t39.8562-6/335648731_142576991793348_7786819189843639239_n.svg?_nc_cat=108&ccb=1-7&_nc_sid=e280be&_nc_ohc=A0acSpNh6E4Q7kNvgGDLofQ&_nc_ht=scontent.fdel1-5.fna&oh=00_AYCkguj7aDwUnaexlAzG7ZkNakRoKt6h8cPvEnmmh8FcYw&oe=66DB986E)![](https://scontent.fdel1-5.fna.fbcdn.net/v/t39.8562-6/335648731_142576991793348_7786819189843639239_n.svg?_nc_cat=108&ccb=1-7&_nc_sid=e280be&_nc_ohc=A0acSpNh6E4Q7kNvgGDLofQ&_nc_ht=scontent.fdel1-5.fna&oh=00_AYCkguj7aDwUnaexlAzG7ZkNakRoKt6h8cPvEnmmh8FcYw&oe=66DB986E)](https://www.youtube.com/@aiatmeta)\\n\\nOur approach\\n\\n __ __\\n\\n[Our approach](/about)[ About AI at\\nMeta](/about)[Responsibility](/responsible-\\nai)[People](/results/?content_types%5B0%5D=person&sort_by=random)[Careers](https://www.metacareers.com/jobs/?is_leadership=0&sub_teams\\\\[0\\\\]=Artificial%20Intelligence&is_in_page=0)\\n\\nResearch\\n\\n __ __\\n\\n[Research](/research)[\\nInfrastructure](/infrastructure)[Resources](/resources)[Demos](https://aidemos.meta.com/)\\n\\nProduct experiences\\n\\n __ __\\n\\n[Meta AI](/meta-ai/)[ AI Studio](/ai-studio/)\\n\\nLatest news\\n\\n __ __\\n\\n[Latest news](/blog)[ Blog](/blog)[Newsletter](/subscribe)\\n\\nFoundational models\\n\\n __ __\\n\\n[Llama](https://llama.meta.com/)\\n\\n[![](https://scontent.fdel1-8.fna.fbcdn.net/v/t39.8562-6/335682312_964107378293184_3093631164486164913_n.svg?_nc_cat=100&ccb=1-7&_nc_sid=e280be&_nc_ohc=erPJUFZABnAQ7kNvgGCpRUQ&_nc_ht=scontent.fdel1-8.fna&oh=00_AYBA750lwGLtnNcHfea2pV3n2jOeOtNA8CE_G8x4XaBnUA&oe=66DB9327)![](https://scontent.fdel1-8.fna.fbcdn.net/v/t39.8562-6/335682312_964107378293184_3093631164486164913_n.svg?_nc_cat=100&ccb=1-7&_nc_sid=e280be&_nc_ohc=erPJUFZABnAQ7kNvgGCpRUQ&_nc_ht=scontent.fdel1-8.fna&oh=00_AYBA750lwGLtnNcHfea2pV3n2jOeOtNA8CE_G8x4XaBnUA&oe=66DB9327)](https://www.facebook.com/aiatmeta/)\\n\\n[![](https://scontent.fdel1-7.fna.fbcdn.net/v/t39.8562-6/336009607_1870102080040414_6753977241281150924_n.svg?_nc_cat=103&ccb=1-7&_nc_sid=e280be&_nc_ohc=SNVlogX_i-\\nUQ7kNvgEfRlYO&_nc_ht=scontent.fdel1-7.fna&oh=00_AYBTiBa9jOXr_bzPnChCA5Z8aTiZBYTR8WTSFG0xuosb7g&oe=66DB8B62)![](https://scontent.fdel1-7.fna.fbcdn.net/v/t39.8562-6/336009607_1870102080040414_6753977241281150924_n.svg?_nc_cat=103&ccb=1-7&_nc_sid=e280be&_nc_ohc=SNVlogX_i-\\nUQ7kNvgEfRlYO&_nc_ht=scontent.fdel1-7.fna&oh=00_AYBTiBa9jOXr_bzPnChCA5Z8aTiZBYTR8WTSFG0xuosb7g&oe=66DB8B62)](https://twitter.com/aiatmeta/)\\n\\n[![](https://scontent.fdel1-6.fna.fbcdn.net/v/t39.8562-6/336289415_1541032296405649_2165099305308791297_n.svg?_nc_cat=109&ccb=1-7&_nc_sid=e280be&_nc_ohc=3SBqtvuqWDIQ7kNvgGZCiep&_nc_ht=scontent.fdel1-6.fna&oh=00_AYAIKEFIlfp_cDxMqPAtQGtNkCgWb5ryVGttMTJiLiiKsA&oe=66DBB73B)![](https://scontent.fdel1-6.fna.fbcdn.net/v/t39.8562-6/336289415_1541032296405649_2165099305308791297_n.svg?_nc_cat=109&ccb=1-7&_nc_sid=e280be&_nc_ohc=3SBqtvuqWDIQ7kNvgGZCiep&_nc_ht=scontent.fdel1-6.fna&oh=00_AYAIKEFIlfp_cDxMqPAtQGtNkCgWb5ryVGttMTJiLiiKsA&oe=66DBB73B)](https://www.linkedin.com/showcase/aiatmeta)\\n\\n[![](https://scontent.fdel1-5.fna.fbcdn.net/v/t39.8562-6/335648731_142576991793348_7786819189843639239_n.svg?_nc_cat=108&ccb=1-7&_nc_sid=e280be&_nc_ohc=A0acSpNh6E4Q7kNvgGDLofQ&_nc_ht=scontent.fdel1-5.fna&oh=00_AYCkguj7aDwUnaexlAzG7ZkNakRoKt6h8cPvEnmmh8FcYw&oe=66DB986E)![](https://scontent.fdel1-5.fna.fbcdn.net/v/t39.8562-6/335648731_142576991793348_7786819189843639239_n.svg?_nc_cat=108&ccb=1-7&_nc_sid=e280be&_nc_ohc=A0acSpNh6E4Q7kNvgGDLofQ&_nc_ht=scontent.fdel1-5.fna&oh=00_AYCkguj7aDwUnaexlAzG7ZkNakRoKt6h8cPvEnmmh8FcYw&oe=66DB986E)](https://www.youtube.com/@aiatmeta)\\n\\n[ Privacy Policy](https://www.facebook.com/about/privacy/)\\n\\n[Terms](https://www.facebook.com/policies/)\\n\\n[Cookies](https://www.facebook.com/policies/cookies/)\\n\\nMeta © 2024\\n\\n[![](https://scontent.fdel1-8.fna.fbcdn.net/v/t39.8562-6/335682312_964107378293184_3093631164486164913_n.svg?_nc_cat=100&ccb=1-7&_nc_sid=e280be&_nc_ohc=erPJUFZABnAQ7kNvgGCpRUQ&_nc_ht=scontent.fdel1-8.fna&oh=00_AYBA750lwGLtnNcHfea2pV3n2jOeOtNA8CE_G8x4XaBnUA&oe=66DB9327)![](https://scontent.fdel1-8.fna.fbcdn.net/v/t39.8562-6/335682312_964107378293184_3093631164486164913_n.svg?_nc_cat=100&ccb=1-7&_nc_sid=e280be&_nc_ohc=erPJUFZABnAQ7kNvgGCpRUQ&_nc_ht=scontent.fdel1-8.fna&oh=00_AYBA750lwGLtnNcHfea2pV3n2jOeOtNA8CE_G8x4XaBnUA&oe=66DB9327)](https://www.facebook.com/aiatmeta/)\\n\\n[![](https://scontent.fdel1-7.fna.fbcdn.net/v/t39.8562-6/336009607_1870102080040414_6753977241281150924_n.svg?_nc_cat=103&ccb=1-7&_nc_sid=e280be&_nc_ohc=SNVlogX_i-\\nUQ7kNvgEfRlYO&_nc_ht=scontent.fdel1-7.fna&oh=00_AYBTiBa9jOXr_bzPnChCA5Z8aTiZBYTR8WTSFG0xuosb7g&oe=66DB8B62)![](https://scontent.fdel1-7.fna.fbcdn.net/v/t39.8562-6/336009607_1870102080040414_6753977241281150924_n.svg?_nc_cat=103&ccb=1-7&_nc_sid=e280be&_nc_ohc=SNVlogX_i-\\nUQ7kNvgEfRlYO&_nc_ht=scontent.fdel1-7.fna&oh=00_AYBTiBa9jOXr_bzPnChCA5Z8aTiZBYTR8WTSFG0xuosb7g&oe=66DB8B62)](https://twitter.com/aiatmeta/)\\n\\n[![](https://scontent.fdel1-6.fna.fbcdn.net/v/t39.8562-6/336289415_1541032296405649_2165099305308791297_n.svg?_nc_cat=109&ccb=1-7&_nc_sid=e280be&_nc_ohc=3SBqtvuqWDIQ7kNvgGZCiep&_nc_ht=scontent.fdel1-6.fna&oh=00_AYAIKEFIlfp_cDxMqPAtQGtNkCgWb5ryVGttMTJiLiiKsA&oe=66DBB73B)![](https://scontent.fdel1-6.fna.fbcdn.net/v/t39.8562-6/336289415_1541032296405649_2165099305308791297_n.svg?_nc_cat=109&ccb=1-7&_nc_sid=e280be&_nc_ohc=3SBqtvuqWDIQ7kNvgGZCiep&_nc_ht=scontent.fdel1-6.fna&oh=00_AYAIKEFIlfp_cDxMqPAtQGtNkCgWb5ryVGttMTJiLiiKsA&oe=66DBB73B)](https://www.linkedin.com/showcase/aiatmeta)\\n\\n[![](https://scontent.fdel1-5.fna.fbcdn.net/v/t39.8562-6/335648731_142576991793348_7786819189843639239_n.svg?_nc_cat=108&ccb=1-7&_nc_sid=e280be&_nc_ohc=A0acSpNh6E4Q7kNvgGDLofQ&_nc_ht=scontent.fdel1-5.fna&oh=00_AYCkguj7aDwUnaexlAzG7ZkNakRoKt6h8cPvEnmmh8FcYw&oe=66DB986E)![](https://scontent.fdel1-5.fna.fbcdn.net/v/t39.8562-6/335648731_142576991793348_7786819189843639239_n.svg?_nc_cat=108&ccb=1-7&_nc_sid=e280be&_nc_ohc=A0acSpNh6E4Q7kNvgGDLofQ&_nc_ht=scontent.fdel1-5.fna&oh=00_AYCkguj7aDwUnaexlAzG7ZkNakRoKt6h8cPvEnmmh8FcYw&oe=66DB986E)](https://www.youtube.com/@aiatmeta)\\n\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Llama3 model with LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex,  Settings\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "ollama_embedding = OllamaEmbedding(\n",
    "    model_name=\"llama3\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0,\"reduce_mem\": True},\n",
    ")\n",
    "Settings.embed_model = ollama_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = Ollama(model=\"llama3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Ollama call failed with status code 500. Details: model requires more system memory (5.1 GiB) than is available (4.7 GiB)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
